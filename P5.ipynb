{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Dataset Exploration\n",
    "### by Mohamad Zeini Jahromi\n",
    "## Introduction\n",
    "Enron Corporation was an American energy, commodities, and services company based in Houston, Texas. Before its bankruptcy on December 2, 2001, Enron employed approximately 20,000 staff and was one of the world's major electricity, natural gas, communications and pulp and paper companies, with claimed revenues of nearly $101 billion during 2000. Fortune named Enron \"America's Most Innovative Company\" for six consecutive years.\n",
    "\n",
    "At the end of 2001, it was revealed that its reported financial condition was sustained by institutionalized, systematic, and creatively planned accounting fraud, known since as the Enron scandal. In the resulting Federal investigation, there was a significant amount of typically confidential information entered into public record, including tens of thousands of emails and detailed financial data for top executives. \n",
    "\n",
    "The objective of this project is to come up with a predictive model for identifying employees who have committed fraud (\"Person of Interest\" or POI). I will explore the Enron email and financial dataset and test different classifiers to find the most accurate one in terms of identifying POI label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "The dataset contained 146 records with 21 financial and email features. POI label is a Boolean label (True or False) and shows whether a person committed fraud or not. 18 out of 146 records were labeled as a \"Person Of Interest\" (POI). The following shows entries for the first person, 'METTS MARK'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries  :  146\n",
      "Number of features :  21\n",
      "Number of POI      :  18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('METTS MARK',\n",
       " {'bonus': 600000,\n",
       "  'deferral_payments': 'NaN',\n",
       "  'deferred_income': 'NaN',\n",
       "  'director_fees': 'NaN',\n",
       "  'email_address': 'mark.metts@enron.com',\n",
       "  'exercised_stock_options': 'NaN',\n",
       "  'expenses': 94299,\n",
       "  'from_messages': 29,\n",
       "  'from_poi_to_this_person': 38,\n",
       "  'from_this_person_to_poi': 1,\n",
       "  'loan_advances': 'NaN',\n",
       "  'long_term_incentive': 'NaN',\n",
       "  'other': 1740,\n",
       "  'poi': False,\n",
       "  'restricted_stock': 585062,\n",
       "  'restricted_stock_deferred': 'NaN',\n",
       "  'salary': 365788,\n",
       "  'shared_receipt_with_poi': 702,\n",
       "  'to_messages': 807,\n",
       "  'total_payments': 1061827,\n",
       "  'total_stock_value': 585062})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "path = \"C:\\Users\\Mo\\Dropbox\\DAND\\P5\\ud120-projects-master\\Final_project\"\n",
    "os.chdir(path)\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "print 'Number of entries  : ', len(data_dict)\n",
    "print 'Number of features : ', len(data_dict.values()[0])\n",
    "poi_tot = 0\n",
    "for k, v in data_dict.items():\n",
    "    if v['poi'] == True:\n",
    "        poi_tot += 1\n",
    "print 'Number of POI      : ', poi_tot\n",
    "data_dict.items()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "Many of features have missing values and assigned 'NaN' as the value entries. The following list shows which features have the most 'NaN' values. I will not include the features with more than 100 'NaN's in the final features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   salary         51\n",
      "              to_messages         60\n",
      "        deferral_payments        107\n",
      "           total_payments         21\n",
      "            loan_advances        142\n",
      "                    bonus         64\n",
      "            email_address         35\n",
      "restricted_stock_deferred        128\n",
      "        total_stock_value         20\n",
      "  shared_receipt_with_poi         60\n",
      "      long_term_incentive         80\n",
      "  exercised_stock_options         44\n",
      "            from_messages         60\n",
      "                    other         53\n",
      "  from_poi_to_this_person         60\n",
      "  from_this_person_to_poi         60\n",
      "                      poi          0\n",
      "          deferred_income         97\n",
      "                 expenses         51\n",
      "         restricted_stock         36\n",
      "            director_fees        129\n"
     ]
    }
   ],
   "source": [
    "dic_nan = {}\n",
    "for key, value in data_dict.items():\n",
    "    for k, v in value.items():\n",
    "        if k not in dic_nan.keys():\n",
    "            dic_nan[k] = 0\n",
    "        if v == 'NaN':\n",
    "            dic_nan[k] += 1\n",
    "for k, v in dic_nan.items(): \n",
    "    print(\"{: >25} {: >10}\".format(*[k, v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "The following table represents the statistical summary of our dataset. First we created a dataframe (first table) and grouped all the entries by 'poi' status and exclude all the 'NaN' values (second table). The significant differences between the average and maximum values, shows where we should look for possible outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mo\\Anaconda3\\envs\\DAND\\lib\\site-packages\\ipykernel\\__main__.py:4: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>4175000.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>201955.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>1729541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>-560222.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>5243487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>239671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>63014.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bonus  deferral_payments  deferred_income  \\\n",
       "ALLEN PHILLIP K     4175000.0          2869717.0       -3081055.0   \n",
       "BADUM JAMES P             NaN           178980.0              NaN   \n",
       "BANNANTINE JAMES M        NaN                NaN          -5104.0   \n",
       "BAXTER JOHN C       1200000.0          1295738.0       -1386055.0   \n",
       "BAY FRANKLIN R       400000.0           260455.0        -201641.0   \n",
       "\n",
       "                    director_fees  email_address  exercised_stock_options  \\\n",
       "ALLEN PHILLIP K               NaN            NaN                1729541.0   \n",
       "BADUM JAMES P                 NaN            NaN                 257817.0   \n",
       "BANNANTINE JAMES M            NaN            NaN                4046157.0   \n",
       "BAXTER JOHN C                 NaN            NaN                6680544.0   \n",
       "BAY FRANKLIN R                NaN            NaN                      NaN   \n",
       "\n",
       "                    expenses  from_messages  from_poi_to_this_person  \\\n",
       "ALLEN PHILLIP K      13868.0         2195.0                     47.0   \n",
       "BADUM JAMES P         3486.0            NaN                      NaN   \n",
       "BANNANTINE JAMES M   56301.0           29.0                     39.0   \n",
       "BAXTER JOHN C        11200.0            NaN                      NaN   \n",
       "BAY FRANKLIN R      129142.0            NaN                      NaN   \n",
       "\n",
       "                    from_this_person_to_poi        ...          \\\n",
       "ALLEN PHILLIP K                        65.0        ...           \n",
       "BADUM JAMES P                           NaN        ...           \n",
       "BANNANTINE JAMES M                      0.0        ...           \n",
       "BAXTER JOHN C                           NaN        ...           \n",
       "BAY FRANKLIN R                          NaN        ...           \n",
       "\n",
       "                    long_term_incentive      other  poi  restricted_stock  \\\n",
       "ALLEN PHILLIP K                304805.0      152.0  0.0          126027.0   \n",
       "BADUM JAMES P                       NaN        NaN  0.0               NaN   \n",
       "BANNANTINE JAMES M                  NaN   864523.0  0.0         1757552.0   \n",
       "BAXTER JOHN C                 1586055.0  2660303.0  0.0         3942714.0   \n",
       "BAY FRANKLIN R                      NaN       69.0  0.0          145796.0   \n",
       "\n",
       "                    restricted_stock_deferred    salary  \\\n",
       "ALLEN PHILLIP K                     -126027.0  201955.0   \n",
       "BADUM JAMES P                             NaN       NaN   \n",
       "BANNANTINE JAMES M                  -560222.0     477.0   \n",
       "BAXTER JOHN C                             NaN  267102.0   \n",
       "BAY FRANKLIN R                       -82782.0  239671.0   \n",
       "\n",
       "                    shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "ALLEN PHILLIP K                      1407.0       2902.0       4484442.0   \n",
       "BADUM JAMES P                           NaN          NaN        182466.0   \n",
       "BANNANTINE JAMES M                    465.0        566.0        916197.0   \n",
       "BAXTER JOHN C                           NaN          NaN       5634343.0   \n",
       "BAY FRANKLIN R                          NaN          NaN        827696.0   \n",
       "\n",
       "                    total_stock_value  \n",
       "ALLEN PHILLIP K             1729541.0  \n",
       "BADUM JAMES P                257817.0  \n",
       "BANNANTINE JAMES M          5243487.0  \n",
       "BAXTER JOHN C              10623258.0  \n",
       "BAY FRANKLIN R                63014.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.convert_objects(convert_numeric=True)\n",
    "df = df.transpose()\n",
    "# df = df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mo\\Anaconda3\\envs\\DAND\\lib\\site-packages\\pandas\\core\\series.py:1340: RuntimeWarning: invalid value encountered in rint\n",
      "  result = _values_from_object(self).round(decimals)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0.0</th>\n",
       "      <th>count</th>\n",
       "      <td>66.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2446776.0</td>\n",
       "      <td>1807789.0</td>\n",
       "      <td>-1170917.0</td>\n",
       "      <td>166805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5390155.0</td>\n",
       "      <td>120150.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28775000.0</td>\n",
       "      <td>1529361.0</td>\n",
       "      <td>946921.0</td>\n",
       "      <td>2322312.0</td>\n",
       "      <td>166411.0</td>\n",
       "      <td>601152.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>4605105.0</td>\n",
       "      <td>6375339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11917761.0</td>\n",
       "      <td>5510228.0</td>\n",
       "      <td>4531597.0</td>\n",
       "      <td>319891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32755564.0</td>\n",
       "      <td>592508.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>47768001.0</td>\n",
       "      <td>6564217.0</td>\n",
       "      <td>4983723.0</td>\n",
       "      <td>13541936.0</td>\n",
       "      <td>4201494.0</td>\n",
       "      <td>2997169.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>2693.0</td>\n",
       "      <td>29904852.0</td>\n",
       "      <td>41730842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>-27992891.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>69223.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>-7576788.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-44093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>87469.0</td>\n",
       "      <td>-581244.0</td>\n",
       "      <td>98784.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450758.0</td>\n",
       "      <td>18834.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>260893.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>213063.0</td>\n",
       "      <td>-389622.0</td>\n",
       "      <td>207216.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>341018.0</td>\n",
       "      <td>428217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>725000.0</td>\n",
       "      <td>382532.0</td>\n",
       "      <td>-123142.0</td>\n",
       "      <td>108579.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1043324.0</td>\n",
       "      <td>46145.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>395480.0</td>\n",
       "      <td>25553.0</td>\n",
       "      <td>417619.0</td>\n",
       "      <td>-146975.0</td>\n",
       "      <td>254570.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>1057548.0</td>\n",
       "      <td>1032338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1066354.0</td>\n",
       "      <td>-37086.0</td>\n",
       "      <td>113784.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2204999.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42962500.0</td>\n",
       "      <td>694862.0</td>\n",
       "      <td>387630.0</td>\n",
       "      <td>934065.0</td>\n",
       "      <td>-75010.0</td>\n",
       "      <td>300230.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>2591.0</td>\n",
       "      <td>2031214.0</td>\n",
       "      <td>2372703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97343619.0</td>\n",
       "      <td>32083396.0</td>\n",
       "      <td>-1042.0</td>\n",
       "      <td>1398517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311764000.0</td>\n",
       "      <td>5235198.0</td>\n",
       "      <td>14368.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>83925000.0</td>\n",
       "      <td>48521928.0</td>\n",
       "      <td>42667589.0</td>\n",
       "      <td>130322299.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>26704229.0</td>\n",
       "      <td>4527.0</td>\n",
       "      <td>15149.0</td>\n",
       "      <td>309886585.0</td>\n",
       "      <td>434509511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1.0</th>\n",
       "      <th>count</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2075000.0</td>\n",
       "      <td>519894.0</td>\n",
       "      <td>-1035313.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10463794.0</td>\n",
       "      <td>59874.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>1204862.0</td>\n",
       "      <td>802997.0</td>\n",
       "      <td>2318621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383445.0</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>7913590.0</td>\n",
       "      <td>9165671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2047437.0</td>\n",
       "      <td>912889.0</td>\n",
       "      <td>1334972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12382588.0</td>\n",
       "      <td>37525.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>991658.0</td>\n",
       "      <td>2417568.0</td>\n",
       "      <td>3620811.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278360.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>23965492.0</td>\n",
       "      <td>13841168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>10259.0</td>\n",
       "      <td>-3504386.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>384728.0</td>\n",
       "      <td>16514.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>71023.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158403.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>91093.0</td>\n",
       "      <td>126027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>775000.0</td>\n",
       "      <td>27610.0</td>\n",
       "      <td>-1860244.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1456581.0</td>\n",
       "      <td>31323.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>368978.0</td>\n",
       "      <td>4980.0</td>\n",
       "      <td>393818.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240189.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>1142396.0</td>\n",
       "      <td>1016450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1275000.0</td>\n",
       "      <td>202911.0</td>\n",
       "      <td>-262500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3914557.0</td>\n",
       "      <td>50448.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>1134637.0</td>\n",
       "      <td>149204.0</td>\n",
       "      <td>985032.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278601.0</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1754028.0</td>\n",
       "      <td>2206836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2062500.0</td>\n",
       "      <td>214678.0</td>\n",
       "      <td>-122031.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19386044.0</td>\n",
       "      <td>84125.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>1646772.0</td>\n",
       "      <td>260772.0</td>\n",
       "      <td>2502063.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415189.0</td>\n",
       "      <td>2165.0</td>\n",
       "      <td>2969.0</td>\n",
       "      <td>2665345.0</td>\n",
       "      <td>10511335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7000000.0</td>\n",
       "      <td>2144013.0</td>\n",
       "      <td>-833.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34348384.0</td>\n",
       "      <td>127017.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>10359729.0</td>\n",
       "      <td>14761694.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1111258.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>7991.0</td>\n",
       "      <td>103559793.0</td>\n",
       "      <td>49110078.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "poi                                                                        \n",
       "0.0 count        66.0               34.0             38.0           17.0   \n",
       "    mean    2446776.0          1807789.0       -1170917.0       166805.0   \n",
       "    std    11917761.0          5510228.0        4531597.0       319891.0   \n",
       "    min       70000.0          -102500.0      -27992891.0         3285.0   \n",
       "    25%      400000.0            87469.0        -581244.0        98784.0   \n",
       "    50%      725000.0           382532.0        -123142.0       108579.0   \n",
       "    75%     1000000.0          1066354.0         -37086.0       113784.0   \n",
       "    max    97343619.0         32083396.0          -1042.0      1398517.0   \n",
       "1.0 count        16.0                5.0             11.0            0.0   \n",
       "    mean    2075000.0           519894.0       -1035313.0            NaN   \n",
       "    std     2047437.0           912889.0        1334972.0            NaN   \n",
       "    min      200000.0            10259.0       -3504386.0            NaN   \n",
       "    25%      775000.0            27610.0       -1860244.0            NaN   \n",
       "    50%     1275000.0           202911.0        -262500.0            NaN   \n",
       "    75%     2062500.0           214678.0        -122031.0            NaN   \n",
       "    max     7000000.0          2144013.0           -833.0            NaN   \n",
       "\n",
       "           email_address  exercised_stock_options   expenses  from_messages  \\\n",
       "poi                                                                           \n",
       "0.0 count            0.0                     90.0       77.0           72.0   \n",
       "    mean             NaN                5390155.0   120150.0          669.0   \n",
       "    std              NaN               32755564.0   592508.0         1979.0   \n",
       "    min              NaN                   3285.0      148.0           12.0   \n",
       "    25%              NaN                 450758.0    18834.0           20.0   \n",
       "    50%              NaN                1043324.0    46145.0           41.0   \n",
       "    75%              NaN                2204999.0    78552.0          216.0   \n",
       "    max              NaN              311764000.0  5235198.0        14368.0   \n",
       "1.0 count            0.0                     12.0       18.0           14.0   \n",
       "    mean             NaN               10463794.0    59874.0          300.0   \n",
       "    std              NaN               12382588.0    37525.0          806.0   \n",
       "    min              NaN                 384728.0    16514.0           16.0   \n",
       "    25%              NaN                1456581.0    31323.0           33.0   \n",
       "    50%              NaN                3914557.0    50448.0           44.0   \n",
       "    75%              NaN               19386044.0    84125.0          102.0   \n",
       "    max              NaN               34348384.0   127017.0         3069.0   \n",
       "\n",
       "           from_poi_to_this_person  from_this_person_to_poi  loan_advances  \\\n",
       "poi                                                                          \n",
       "0.0 count                     72.0                     72.0            3.0   \n",
       "    mean                      58.0                     36.0     28775000.0   \n",
       "    std                       88.0                     85.0     47768001.0   \n",
       "    min                        0.0                      0.0       400000.0   \n",
       "    25%                       10.0                      0.0      1200000.0   \n",
       "    50%                       26.0                      6.0      2000000.0   \n",
       "    75%                       62.0                     23.0     42962500.0   \n",
       "    max                      528.0                    411.0     83925000.0   \n",
       "1.0 count                     14.0                     14.0            1.0   \n",
       "    mean                      98.0                     67.0     81525000.0   \n",
       "    std                       76.0                    158.0            NaN   \n",
       "    min                       13.0                      4.0     81525000.0   \n",
       "    25%                       44.0                     12.0     81525000.0   \n",
       "    50%                       62.0                     16.0     81525000.0   \n",
       "    75%                      136.0                     29.0     81525000.0   \n",
       "    max                      240.0                    609.0     81525000.0   \n",
       "\n",
       "           long_term_incentive       other  restricted_stock  \\\n",
       "poi                                                            \n",
       "0.0 count                 54.0        75.0              93.0   \n",
       "    mean             1529361.0    946921.0         2322312.0   \n",
       "    std              6564217.0   4983723.0        13541936.0   \n",
       "    min                69223.0         2.0        -2604490.0   \n",
       "    25%               260893.0       960.0          213063.0   \n",
       "    50%               395480.0     25553.0          417619.0   \n",
       "    75%               694862.0    387630.0          934065.0   \n",
       "    max             48521928.0  42667589.0       130322299.0   \n",
       "1.0 count                 12.0        18.0              17.0   \n",
       "    mean             1204862.0    802997.0         2318621.0   \n",
       "    std               991658.0   2417568.0         3620811.0   \n",
       "    min                71023.0       486.0          126027.0   \n",
       "    25%               368978.0      4980.0          393818.0   \n",
       "    50%              1134637.0    149204.0          985032.0   \n",
       "    75%              1646772.0    260772.0         2502063.0   \n",
       "    max              3600000.0  10359729.0        14761694.0   \n",
       "\n",
       "           restricted_stock_deferred      salary  shared_receipt_with_poi  \\\n",
       "poi                                                                         \n",
       "0.0 count                       18.0        78.0                     72.0   \n",
       "    mean                    166411.0    601152.0                   1059.0   \n",
       "    std                    4201494.0   2997169.0                   1133.0   \n",
       "    min                   -7576788.0       477.0                      2.0   \n",
       "    25%                    -389622.0    207216.0                    192.0   \n",
       "    50%                    -146975.0    254570.0                    594.0   \n",
       "    75%                     -75010.0    300230.0                   1636.0   \n",
       "    max                   15456290.0  26704229.0                   4527.0   \n",
       "1.0 count                        0.0        17.0                     14.0   \n",
       "    mean                         NaN    383445.0                   1783.0   \n",
       "    std                          NaN    278360.0                   1265.0   \n",
       "    min                          NaN    158403.0                     91.0   \n",
       "    25%                          NaN    240189.0                   1059.0   \n",
       "    50%                          NaN    278601.0                   1589.0   \n",
       "    75%                          NaN    415189.0                   2165.0   \n",
       "    max                          NaN   1111258.0                   5521.0   \n",
       "\n",
       "           to_messages  total_payments  total_stock_value  \n",
       "poi                                                        \n",
       "0.0 count         72.0           107.0              108.0  \n",
       "    mean        2007.0       4605105.0          6375339.0  \n",
       "    std         2693.0      29904852.0         41730842.0  \n",
       "    min           57.0           148.0           -44093.0  \n",
       "    25%          514.0        341018.0           428217.0  \n",
       "    50%          944.0       1057548.0          1032338.0  \n",
       "    75%         2591.0       2031214.0          2372703.0  \n",
       "    max        15149.0     309886585.0        434509511.0  \n",
       "1.0 count         14.0            18.0               18.0  \n",
       "    mean        2417.0       7913590.0          9165671.0  \n",
       "    std         1962.0      23965492.0         13841168.0  \n",
       "    min          225.0         91093.0           126027.0  \n",
       "    25%         1116.0       1142396.0          1016450.0  \n",
       "    50%         1875.0       1754028.0          2206836.0  \n",
       "    75%         2969.0       2665345.0         10511335.0  \n",
       "    max         7991.0     103559793.0         49110078.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['poi']).describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the outliers by plotting \"salary\" vs. \"bonus\" features. Also we will print out persons with 'salary' above 1 million dollars and 'bonus' above 10 million dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAH6CAYAAADiEUG6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x91bca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LAY KENNETH L         1072321         7000000            True\n",
      "  SKILLING JEFFREY K         1111258         5600000            True\n",
      "               TOTAL        26704229        97343619           False\n",
      "      FREVERT MARK A         1060932         2000000           False\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    plt.scatter( salary, bonus )\n",
    "\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\")\n",
    "plt.show()\n",
    "\n",
    "for k, v in data_dict.items():\n",
    "     if (v['salary'] != 'NaN' and v['salary'] > 10**6) or (v['bonus'] != 'NaN' and v['bonus'] > 10**7): \n",
    "            print(\"{: >20} {: >15} {: >15} {: >15}\".format(*[k, v['salary'], v['bonus'], str(v['poi'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously 'TOTAL' entry is an extreme outlier and is not a real person and we will remove it from the dataset. Jefferey Skilling, Kenneth Lay are notable guys related to the fraud case. Next, we replot the data points for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAH6CAYAAAD82HEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x793d358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dict.pop('TOTAL', 0)\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    plt.scatter( salary, bonus )\n",
    "\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features\n",
    "\n",
    "Before we create and engineer new features, let's look at our features list along with their scores. I used 'SelectKBest' to select top 10 most effective features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  exercised_stock_options             25.0975415287\n",
      "        total_stock_value             24.4676540475\n",
      "                    bonus             21.0600017075\n",
      "                   salary              18.575703268\n",
      "          deferred_income             11.5955476597\n",
      "      long_term_incentive             10.0724545294\n",
      "         restricted_stock             9.34670079105\n",
      "           total_payments             8.86672153711\n",
      "  shared_receipt_with_poi             8.74648553213\n",
      "                 expenses             6.23420114051\n",
      "  from_poi_to_this_person             5.34494152315\n",
      "                    other              4.2049708583\n",
      "  from_this_person_to_poi             2.42650812724\n",
      "              to_messages             1.69882434858\n",
      "            from_messages            0.164164498234\n"
     ]
    }
   ],
   "source": [
    "my_features = ['poi', 'salary', 'total_payments', 'bonus',\n",
    "               'total_stock_value', 'shared_receipt_with_poi', \n",
    "               'long_term_incentive', 'exercised_stock_options', 'other', \n",
    "               'deferred_income', 'expenses', 'restricted_stock',\n",
    "               'from_poi_to_this_person', 'from_this_person_to_poi', \n",
    "               'from_messages', 'to_messages']\n",
    "\n",
    "my_dataset = data_dict\n",
    "data = featureFormat(my_dataset, my_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# K-best features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "k_features = SelectKBest(k=10)\n",
    "k_features.fit(features, labels)\n",
    "\n",
    "k_list = zip(k_features.get_support(), my_features[1:], k_features.scores_)\n",
    "k_list = sorted(k_list, key=lambda x: x[2], reverse=True)\n",
    "for i in k_list: \n",
    "    print(\"{: >25} {: >25}\".format(*[i[1], i[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the 'from_this_person_to_poi' and 'from_poi_to_this_person' by the total number of emails sent and received, respectively, might help us identify those have low amounts of email activity overall, but a high percentage of email activity with POI's. \n",
    "\n",
    "In addition to our initial feature list, I created two new features based on number of emails 'sent to' or 'received from' POI features as follows:\n",
    "* fraction_from_poi\n",
    "* fraction_to_poi\n",
    "\n",
    "The following list shows our new features list along with their respective score. Although our two new features have higher scores than previous ones but they are still in lower part of our features list and might not be included in the final feature set. Also, I want to point out that 'shared_receipt_with_poi' feature have higher score than our new features and represents stronger relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  exercised_stock_options             25.0975415287\n",
      "        total_stock_value             24.4676540475\n",
      "                    bonus             21.0600017075\n",
      "                   salary              18.575703268\n",
      "          deferred_income             11.5955476597\n",
      "      long_term_incentive             10.0724545294\n",
      "         restricted_stock             9.34670079105\n",
      "           total_payments             8.86672153711\n",
      "  shared_receipt_with_poi             8.74648553213\n",
      "                 expenses             6.23420114051\n",
      "        fraction_from_poi             5.34494152315\n",
      "                    other              4.2049708583\n",
      "          fraction_to_poi             2.42650812724\n"
     ]
    }
   ],
   "source": [
    "for k, v in my_dataset.items():\n",
    "    from_poi_to_this_person = v[\"from_poi_to_this_person\"]\n",
    "    to_messages = v[\"to_messages\"]\n",
    "    \n",
    "    fraction = 0. \n",
    "    if from_poi_to_this_person != 'NaN' and to_messages != 'NaN':\n",
    "        fraction_from_poi = float(from_poi_to_this_person) / to_messages\n",
    "    my_dataset[k][\"fraction_from_poi\"] = fraction_from_poi\n",
    "\n",
    "\n",
    "    from_this_person_to_poi = v[\"from_this_person_to_poi\"]\n",
    "    from_messages = v[\"from_messages\"]\n",
    "    if from_this_person_to_poi != 'NaN' and from_messages != 'NaN':\n",
    "        fraction_to_poi = float(from_this_person_to_poi) / from_messages\n",
    "    my_dataset[k][\"fraction_to_poi\"] = fraction_to_poi\n",
    "\n",
    "my_features = ['poi', 'salary', 'total_payments', 'bonus',\n",
    "               'total_stock_value', 'shared_receipt_with_poi', \n",
    "               'long_term_incentive', 'exercised_stock_options', 'other', \n",
    "               'deferred_income', 'expenses', 'restricted_stock', \n",
    "               'fraction_from_poi', 'fraction_to_poi']\n",
    "\n",
    "# K-best features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "k_features = SelectKBest(k=10)\n",
    "k_features.fit(features, labels)\n",
    "\n",
    "k_list = zip(k_features.get_support(), my_features[1:], k_features.scores_)\n",
    "k_list = sorted(k_list, key=lambda x: x[2], reverse=True)\n",
    "for i in k_list: \n",
    "    print(\"{: >25} {: >25}\".format(*[i[1], i[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection process\n",
    "\n",
    "I used two feature selection process, select K-Best and PCA, to select the best features. Select k-best removes all but the k highest scoring features and PCA is a process of transforming the data and projecting it to a lower dimensional space. We iterate between different number of K-Best and PCA to find the optimum number of features. The following are functions to perform the iteration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "def find_kbest(grid_search, features, labels, parameters): \n",
    "    for i in range(2, 6):\n",
    "        print \"================ K best features, k = {0} ================\".format(i)\n",
    "        kb = SelectKBest(k = i)\n",
    "        k_features = kb.fit_transform(features, labels)       \n",
    "        k_list = zip(kb.get_support(), my_features[1:], kb.scores_)\n",
    "        k_list = sorted(k_list, key=lambda x: x[2], reverse=True)\n",
    "        for item in k_list: \n",
    "            if item[0] == True: print item[1:]        \n",
    "        cross_val(grid_search, k_features, labels, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "def doPCA(grid_search, features, labels, parameters):    \n",
    "    for i in range(2, 6):\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "        print \"========= Principal Components features, n = {0} =========\".format(i)    \n",
    "        pca = PCA(n_components = i)\n",
    "        pca.fit(features_train)\n",
    "        pca_features = pca.transform(features)\n",
    "        cross_val(grid_search, pca_features, labels, parameters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Selection of algorithms \n",
    "\n",
    "I will use four algorithms along with the parameter tuning process to find the most accurate and predictive model. The algorithms used are as follows:\n",
    "\n",
    "* Random Forest Classifier\n",
    "* Decision Tree Classifier\n",
    "* AdaBoost Classifier\n",
    "* Gaussian Naive Bayse Classifier\n",
    "\n",
    "##  Parameters tuning  \n",
    "\n",
    "In addition to the feature selection process by K-Best and PCA, the grid search function has been used to assign different number of parameters and choose the best classifier to maximize the precision and recall and the overall accuracy.\n",
    "\n",
    "Grid search function construct a grid of all the combinations of parameters, tries each combination, and then reports back the best combination for specific algorithm.\n",
    "\n",
    "Parameters tuning refers to the adjustment of the algorithm when training, in order to improve the fit on the test set. Parameter can influence the outcome of the learning process, the more tuned the parameters, the more biased the algorithm will be to the training data and test harness. The strategy can be effective but it can also lead to more fragile models and overfit the test harness but don't perform well in practice. For every algorithms, I tried to tune couple of effective paremeters.\n",
    "\n",
    "## Cross validation\n",
    "\n",
    "The purpose of cross validation is to test the model multiple times and make balance between model bias and variance. Overfitting, occurs when we have a high variance in our model and is one of the most challenging things to avoid from in machine learning. \n",
    "\n",
    "Cross validation enable us to first fit a model on a portion of our data set (train) and then try the model on the remainder of the dataset (test) and calculate the overall accuracy. \n",
    "\n",
    "I used Stratified Shuffle Split cross validation with the test size of 30% to evaluate prediction accuracy of different classifiers. This algorithm essentially creates multiple train and test datasets out of our dataset and calculate the overall performance.\n",
    "\n",
    "We are using \"recall\" and \"precision\" parameters to evaluate our classifier's prediction performance. Recall is the ability of classifier to identify all the positive values while precision is its ability to not falsely assign positive values to those values that are actually negative. Using these two we can understand how accurate our model is in identifying the POI persons within the entire dataset.\n",
    "\n",
    "The following shows Stratified Shuffle Split cross validation used in our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def cross_val(grid_search, features, labels, parameters):\n",
    "    \n",
    "    cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "    acc, precision, recall, fscore, support = [], [], [], [], []\n",
    "\n",
    "    for train_indices, test_indices in cv:\n",
    "        #make training and testing sets\n",
    "        features_train= [features[ii] for ii in train_indices]\n",
    "        features_test= [features[ii] for ii in test_indices]\n",
    "        labels_train=[labels[ii] for ii in train_indices]\n",
    "        labels_test=[labels[ii] for ii in test_indices]\n",
    "\n",
    "        grid_search.fit(features_train, labels_train)\n",
    "        predictions = grid_search.predict(features_test)\n",
    "        \n",
    "        acc += [accuracy_score(predictions, labels_test)]\n",
    "        report = precision_recall_fscore_support(labels_test, predictions)\n",
    "        precision += [report[0][1]]\n",
    "        recall += [report[1][1]]\n",
    "        fscore += [report[2][1]]\n",
    "        support += [report[3][1]]\n",
    "    print '=================================='\n",
    "    print 'Accuracy:', mean(acc)\n",
    "    print 'Precision:', mean(precision)\n",
    "    print 'Recall:', mean(recall)\n",
    "    print 'Fscore:', mean(fscore)\n",
    "    print 'Support:', mean(support)\n",
    "    #print classification_report(labels_test, predictions)\n",
    "    if len(parameters.keys()) != 0:\n",
    "        print '========= Best Parameters ========='\n",
    "        best_params = grid_search.best_estimator_.get_params()\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print '%s=%r, ' % (param_name, best_params[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "For start, we try Random Forest Classifier along with the parameter tuning function (Grid Search). We iterate through two loops of features selection (K-Best and PCA) to find the best combination of features and algorithm's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ K best features, k = 2 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "==================================\n",
      "Accuracy: 0.842666666667\n",
      "Precision: 0.215333333333\n",
      "Recall: 0.155\n",
      "Fscore: 0.173523809524\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-15, \n",
      "min_samples_split=3, \n",
      "n_estimators=2, \n",
      "warm_start=False, \n",
      "================ K best features, k = 3 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "==================================\n",
      "Accuracy: 0.872\n",
      "Precision: 0.384833333333\n",
      "Recall: 0.28\n",
      "Fscore: 0.308714285714\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-07, \n",
      "min_samples_split=5, \n",
      "n_estimators=10, \n",
      "warm_start=False, \n",
      "================ K best features, k = 4 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "==================================\n",
      "Accuracy: 0.854\n",
      "Precision: 0.2575\n",
      "Recall: 0.17\n",
      "Fscore: 0.197\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-07, \n",
      "min_samples_split=2, \n",
      "n_estimators=10, \n",
      "warm_start=True, \n",
      "================ K best features, k = 5 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "('deferred_income', 11.732698076065354)\n",
      "==================================\n",
      "Accuracy: 0.855333333333\n",
      "Precision: 0.209166666667\n",
      "Recall: 0.17\n",
      "Fscore: 0.18\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-07, \n",
      "min_samples_split=5, \n",
      "n_estimators=10, \n",
      "warm_start=False, \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators':[2,5,10], 'min_samples_split': [2,3,5], \n",
    "              'min_impurity_split' : [1e-7,1e-15,1e-20],'warm_start' : [True, False]}\n",
    "clf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(clf, parameters)\n",
    "find_kbest(grid_search, features, labels, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Principal Components features, n = 2 =========\n",
      "==================================\n",
      "Accuracy: 0.83\n",
      "Precision: 0.115\n",
      "Recall: 0.085\n",
      "Fscore: 0.0936666666667\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-07, \n",
      "min_samples_split=5, \n",
      "n_estimators=10, \n",
      "warm_start=True, \n",
      "========= Principal Components features, n = 3 =========\n",
      "==================================\n",
      "Accuracy: 0.849333333333\n",
      "Precision: 0.1625\n",
      "Recall: 0.145\n",
      "Fscore: 0.145333333333\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-15, \n",
      "min_samples_split=2, \n",
      "n_estimators=2, \n",
      "warm_start=False, \n",
      "========= Principal Components features, n = 4 =========\n",
      "==================================\n",
      "Accuracy: 0.833333333333\n",
      "Precision: 0.12\n",
      "Recall: 0.085\n",
      "Fscore: 0.0953333333333\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-20, \n",
      "min_samples_split=5, \n",
      "n_estimators=10, \n",
      "warm_start=False, \n",
      "========= Principal Components features, n = 5 =========\n",
      "==================================\n",
      "Accuracy: 0.852\n",
      "Precision: 0.154166666667\n",
      "Recall: 0.12\n",
      "Fscore: 0.126666666667\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "min_impurity_split=1e-20, \n",
      "min_samples_split=3, \n",
      "n_estimators=2, \n",
      "warm_start=True, \n"
     ]
    }
   ],
   "source": [
    "doPCA(grid_search, features, labels, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier\n",
    "AdaBoost Classifier is the second classifier we are trying. Here again the parameter tuning function (Grid Search) and two loops of features selection (K-Best and PCA) has been used to find the best combination of features and algorithm's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ K best features, k = 2 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "==================================\n",
      "Accuracy: 0.880666666667\n",
      "Precision: 0.308333333333\n",
      "Recall: 0.175\n",
      "Fscore: 0.219\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME.R', \n",
      "learning_rate=0.5, \n",
      "n_estimators=20, \n",
      "================ K best features, k = 3 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "==================================\n",
      "Accuracy: 0.858\n",
      "Precision: 0.259166666667\n",
      "Recall: 0.17\n",
      "Fscore: 0.198\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME', \n",
      "learning_rate=0.5, \n",
      "n_estimators=40, \n",
      "================ K best features, k = 4 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "==================================\n",
      "Accuracy: 0.854666666667\n",
      "Precision: 0.242023809524\n",
      "Recall: 0.16\n",
      "Fscore: 0.182444444444\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME', \n",
      "learning_rate=0.5, \n",
      "n_estimators=20, \n",
      "================ K best features, k = 5 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "('deferred_income', 11.732698076065354)\n",
      "==================================\n",
      "Accuracy: 0.859333333333\n",
      "Precision: 0.278333333333\n",
      "Recall: 0.18\n",
      "Fscore: 0.211\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME', \n",
      "learning_rate=0.5, \n",
      "n_estimators=10, \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "parameters = {'n_estimators': [10, 20, 40],\n",
    "               'algorithm': ['SAMME', 'SAMME.R'],\n",
    "               'learning_rate': [.5, 1, 1.5]}\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "grid_search = GridSearchCV(clf, parameters)\n",
    "find_kbest(grid_search, features, labels, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Principal Components features, n = 2 =========\n",
      "==================================\n",
      "Accuracy: 0.861333333333\n",
      "Precision: 0.14\n",
      "Recall: 0.07\n",
      "Fscore: 0.0933333333333\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME', \n",
      "learning_rate=0.5, \n",
      "n_estimators=10, \n",
      "========= Principal Components features, n = 3 =========\n",
      "==================================\n",
      "Accuracy: 0.86\n",
      "Precision: 0.13\n",
      "Recall: 0.065\n",
      "Fscore: 0.0866666666667\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME', \n",
      "learning_rate=0.5, \n",
      "n_estimators=20, \n",
      "========= Principal Components features, n = 4 =========\n",
      "==================================\n",
      "Accuracy: 0.845333333333\n",
      "Precision: 0.109166666667\n",
      "Recall: 0.075\n",
      "Fscore: 0.0846666666667\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME', \n",
      "learning_rate=0.5, \n",
      "n_estimators=10, \n",
      "========= Principal Components features, n = 5 =========\n",
      "==================================\n",
      "Accuracy: 0.845333333333\n",
      "Precision: 0.109166666667\n",
      "Recall: 0.09\n",
      "Fscore: 0.093\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "algorithm='SAMME', \n",
      "learning_rate=0.5, \n",
      "n_estimators=40, \n"
     ]
    }
   ],
   "source": [
    "doPCA(grid_search, features, labels, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "Decision Tree Classifier is the third classifier we are testing on our dataset. The parameter tuning function (Grid Search) and two loops of features selection (K-Best and PCA) are being used to find the best combination of features and algorithm's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ K best features, k = 2 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "==================================\n",
      "Accuracy: 0.87\n",
      "Precision: 0.18\n",
      "Recall: 0.095\n",
      "Fscore: 0.123333333333\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='entropy', \n",
      "max_depth=2, \n",
      "max_leaf_nodes=None, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=2, \n",
      "================ K best features, k = 3 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "==================================\n",
      "Accuracy: 0.836666666667\n",
      "Precision: 0.162833333333\n",
      "Recall: 0.12\n",
      "Fscore: 0.128523809524\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='gini', \n",
      "max_depth=2, \n",
      "max_leaf_nodes=None, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=20, \n",
      "================ K best features, k = 4 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "==================================\n",
      "Accuracy: 0.832\n",
      "Precision: 0.0761666666667\n",
      "Recall: 0.06\n",
      "Fscore: 0.0620238095238\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='gini', \n",
      "max_depth=2, \n",
      "max_leaf_nodes=None, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=10, \n",
      "================ K best features, k = 5 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "('deferred_income', 11.732698076065354)\n",
      "==================================\n",
      "Accuracy: 0.836666666667\n",
      "Precision: 0.182833333333\n",
      "Recall: 0.135\n",
      "Fscore: 0.145857142857\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='gini', \n",
      "max_depth=2, \n",
      "max_leaf_nodes=None, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=20, \n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "               'min_samples_split': [2, 10, 20],\n",
    "               'max_depth': [None, 2, 5, 10],\n",
    "               'min_samples_leaf': [1, 5, 10],\n",
    "               'max_leaf_nodes': [None, 5, 10, 20]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(clf, parameters)\n",
    "find_kbest(grid_search, features, labels, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Principal Components features, n = 2 =========\n",
      "==================================\n",
      "Accuracy: 0.846666666667\n",
      "Precision: 0.02\n",
      "Recall: 0.015\n",
      "Fscore: 0.0166666666667\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='gini', \n",
      "max_depth=None, \n",
      "max_leaf_nodes=5, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=2, \n",
      "========= Principal Components features, n = 3 =========\n",
      "==================================\n",
      "Accuracy: 0.853333333333\n",
      "Precision: 0.0883333333333\n",
      "Recall: 0.07\n",
      "Fscore: 0.0743333333333\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='gini', \n",
      "max_depth=5, \n",
      "max_leaf_nodes=20, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=2, \n",
      "========= Principal Components features, n = 4 =========\n",
      "==================================\n",
      "Accuracy: 0.841333333333\n",
      "Precision: 0.0308333333333\n",
      "Recall: 0.025\n",
      "Fscore: 0.0256666666667\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='entropy', \n",
      "max_depth=2, \n",
      "max_leaf_nodes=None, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=2, \n",
      "========= Principal Components features, n = 5 =========\n",
      "==================================\n",
      "Accuracy: 0.836\n",
      "Precision: 0.0291666666667\n",
      "Recall: 0.025\n",
      "Fscore: 0.0246666666667\n",
      "Support: 2.0\n",
      "========= Best Parameters =========\n",
      "criterion='gini', \n",
      "max_depth=2, \n",
      "max_leaf_nodes=10, \n",
      "min_samples_leaf=1, \n",
      "min_samples_split=2, \n"
     ]
    }
   ],
   "source": [
    "doPCA(grid_search, features, labels, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayse\n",
    "Finally, we are trying Gaussian Naive Bayse on our dataset. Since we don't have many options for parameter tuning, we used the default values. Two loops of features selection (K-Best and PCA) are being used to find the best combination of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ K best features, k = 2 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "==================================\n",
      "Accuracy: 0.856666666667\n",
      "Precision: 0.326666666667\n",
      "Recall: 0.245\n",
      "Fscore: 0.267333333333\n",
      "Support: 2.0\n",
      "================ K best features, k = 3 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "==================================\n",
      "Accuracy: 0.849333333333\n",
      "Precision: 0.365\n",
      "Recall: 0.305\n",
      "Fscore: 0.313666666667\n",
      "Support: 2.0\n",
      "================ K best features, k = 4 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "==================================\n",
      "Accuracy: 0.848666666667\n",
      "Precision: 0.356666666667\n",
      "Recall: 0.305\n",
      "Fscore: 0.311666666667\n",
      "Support: 2.0\n",
      "================ K best features, k = 5 ================\n",
      "('exercised_stock_options', 25.380105299760199)\n",
      "('total_stock_value', 24.752523020258508)\n",
      "('bonus', 21.327890413979102)\n",
      "('salary', 18.861795316466416)\n",
      "('deferred_income', 11.732698076065354)\n",
      "==================================\n",
      "Accuracy: 0.866\n",
      "Precision: 0.473666666667\n",
      "Recall: 0.37\n",
      "Fscore: 0.393857142857\n",
      "Support: 2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "parameters = {}\n",
    "clf = GaussianNB()\n",
    "find_kbest(clf, features, labels, parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Principal Components features, n = 2 =========\n",
      "==================================\n",
      "Accuracy: 0.848\n",
      "Precision: 0.025\n",
      "Recall: 0.015\n",
      "Fscore: 0.0183333333333\n",
      "Support: 2.0\n",
      "========= Principal Components features, n = 3 =========\n",
      "==================================\n",
      "Accuracy: 0.853333333333\n",
      "Precision: 0.118333333333\n",
      "Recall: 0.085\n",
      "Fscore: 0.0943333333333\n",
      "Support: 2.0\n",
      "========= Principal Components features, n = 4 =========\n",
      "==================================\n",
      "Accuracy: 0.844\n",
      "Precision: 0.0408333333333\n",
      "Recall: 0.03\n",
      "Fscore: 0.0323333333333\n",
      "Support: 2.0\n",
      "========= Principal Components features, n = 5 =========\n",
      "==================================\n",
      "Accuracy: 0.836\n",
      "Precision: 0.0241666666667\n",
      "Recall: 0.025\n",
      "Fscore: 0.023\n",
      "Support: 2.0\n"
     ]
    }
   ],
   "source": [
    "doPCA(grid_search, features, labels, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion \n",
    "In this project, we have evaluated and tested four different algorithms on our dataset. We applied parameters tuning function and iterate through two features selection loops (K-Best and PCA) to find the most predictive and accurate model. \n",
    "\n",
    "The precision and recall were used as the evaluation metrics. Precision is how often our class prediction (POI vs. non-POI) is right when we guess that class. Recall is how often we guess the class (POI vs. non-POI) when the class actually occurred. Due to the nature of the dataset, it is more important to make sure we don't miss any POI's and here accuracy is not a good measurement as even if non-POI are all flagged, the accuracy score will yield that the model is a success.\n",
    "\n",
    "In our cross validation algorithm, I used 100 iterations to calculate the precision and recall values and I reported the means of these values at the end. On the other hand, the cross validation provided in 'tester.py' file uses StratifiedShuffleSplit method with 1000 folds and also uses the cumulative predictions and test results to calculate the precision and recall parameters and therefore it returns even better evaluation metrics.\n",
    "\n",
    "For these reason, I picked the top two classifiers and checked the evaluation metrics using provided 'tester.py' file to see which one is better. \n",
    "\n",
    "The top two classifiers with tuned parameters and selected features are as follows:\n",
    "\n",
    "### Gaussian Naive Bayse with K-best features (k = 5) \n",
    "\n",
    "** Precision :**  0.47\n",
    "\n",
    "** Recall  :**  0.37 \n",
    "\n",
    "** Selected features :** \n",
    "\n",
    "* exercised_stock_options\n",
    "* total_stock_value\n",
    "* bonus\n",
    "* salary\n",
    "* deferred_income\n",
    "\n",
    "### Random Forest Classifier with K-best features (k = 3) \n",
    "\n",
    "** Precision :**  0.38\n",
    "\n",
    "** Recall  :**  0.28 \n",
    "\n",
    "** Selected features :** \n",
    "\n",
    "* exercised_stock_options\n",
    "* total_stock_value\n",
    "* bonus\n",
    "\n",
    "** Optimum tuned parameters:** \n",
    "\n",
    "* n_estimators        : 10\n",
    "* min_samples_split   : 5 \n",
    "* min_impurity_split  : 1e-7\n",
    "* warm_start          : False\n",
    "\n",
    "After saving our dataset, features list and classifier we ran the provided 'tester.py' to see the final evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.85464\tPrecision: 0.48876\tRecall: 0.38050\tF1: 0.42789\tF2: 0.39814\n",
      "\tTotal predictions: 14000\tTrue positives:  761\tFalse positives:  796\tFalse negatives: 1239\tTrue negatives: 11204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tester import dump_classifier_and_data\n",
    "my_features = ['poi', 'exercised_stock_options', 'total_stock_value', 'bonus',\n",
    "              'salary', 'deferred_income']\n",
    "clf = GaussianNB()\n",
    "dump_classifier_and_data(clf, my_dataset, my_features)\n",
    "%run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.86415\tPrecision: 0.60675\tRecall: 0.33250\tF1: 0.42959\tF2: 0.36555\n",
      "\tTotal predictions: 13000\tTrue positives:  665\tFalse positives:  431\tFalse negatives: 1335\tTrue negatives: 10569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tester import dump_classifier_and_data\n",
    "my_features = ['poi', 'exercised_stock_options', 'total_stock_value', 'bonus']\n",
    "clf = RandomForestClassifier(min_impurity_split=1e-07, min_samples_split=5,  \n",
    "                             n_estimators=10, warm_start=False)\n",
    "dump_classifier_and_data(clf, my_dataset, my_features)\n",
    "%run tester.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier** with the following K-best features (k = 3) and tuned parameters has higher Precision (0.60) and Recall (0.33) values and we recommend this classifier as our final predictive model.\n",
    "\n",
    "** Precision :**  0.38\n",
    "\n",
    "** Recall  :**  0.28 \n",
    "\n",
    "** Selected features :** \n",
    "\n",
    "* exercised_stock_options\n",
    "* total_stock_value\n",
    "* bonus\n",
    "\n",
    "** Optimum tuned parameters:** \n",
    "\n",
    "* n_estimators        : 10\n",
    "* min_samples_split   : 5 \n",
    "* min_impurity_split  : 1e-7\n",
    "* warm_start          : False"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
